{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Double Integrator Example\n",
    "In this example, we use Differentiable MPC to recover the parameters in cost function weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import casadi as ca\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from acados_template import AcadosModel, AcadosOcp, AcadosOcpSolver\n",
    "\n",
    "from utils.mpc.mpc_layer import AcadosMpcLayer"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "source": [
    "dt = 0.01\n",
    "N = 100\n",
    "Tf = dt * N\n",
    "Q_mat = np.diag([1e2, 1e1])\n",
    "Qf_mat = Q_mat\n",
    "target_state = np.array([10., 0.])\n",
    "target_input = np.array([0.])\n",
    "max_force = 500.\n",
    "min_force = -max_force"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `AcadosModel`, `AcadosOcp` and `AcadosOcpSolver` objects required for a simple double integrator. The parameters in the OCP is the cost weight of the control input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "source": [
    "# define a simple double integrator\n",
    "def create_acados_model() -> AcadosModel:\n",
    "    pos = ca.SX.sym('pos', 1)\n",
    "    vel = ca.SX.sym('vel', 1)\n",
    "    x = ca.vertcat(pos, vel)\n",
    "    \n",
    "    force = ca.SX.sym('force', 1)\n",
    "    u = ca.vertcat(force)\n",
    "    \n",
    "    r_diag = ca.SX.sym('r_diag')\n",
    "    p = ca.vertcat(r_diag)\n",
    "    \n",
    "    m = 1.  # kg\n",
    "    pos_dot = x[1]\n",
    "    vel_dot = u / m\n",
    "    x_dot = ca.vertcat(pos_dot, vel_dot)\n",
    "    \n",
    "    dynamics_fun = ca.Function('f', [x, u, p], [x_dot])\n",
    "\n",
    "    # dynamics\n",
    "    f_expl = x_dot\n",
    "    k1 = dynamics_fun(x, u, p)\n",
    "    k2 = dynamics_fun(x + dt/2*k1, u, p)\n",
    "    k3 = dynamics_fun(x + dt/2*k2, u, p)\n",
    "    k4 = dynamics_fun(x + dt*k3, u, p)\n",
    "    xplus = x + dt/6 * (k1 + 2*k2 + 2*k3 + k4)\n",
    "\n",
    "    model = AcadosModel()\n",
    "    model.f_expl_expr = f_expl\n",
    "    model.disc_dyn_expr = xplus\n",
    "    model.x = x\n",
    "    model.u = u\n",
    "    model.p = p\n",
    "    model.name = 'double_integrator'\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_acados_ocp() -> AcadosOcp:\n",
    "    # create ocp object to formulate the OCP\n",
    "    ocp = AcadosOcp()\n",
    "\n",
    "    # set model\n",
    "    model = create_acados_model()\n",
    "    ocp.model = model\n",
    "\n",
    "    # set dimensions\n",
    "    ocp.dims.N = N\n",
    "    nx = model.x.rows()\n",
    "    nu = model.u.rows()\n",
    "\n",
    "    # set cost\n",
    "    ocp.cost.cost_type = 'EXTERNAL'\n",
    "    ocp.cost.cost_type_e = 'EXTERNAL'\n",
    "    ocp.model.cost_expr_ext_cost = 1 / 2 * (ocp.model.x - target_state).T @ Q_mat @ (ocp.model.x - target_state) \\\n",
    "                                   + 1 / 2 * (ocp.model.u - target_input).T @ model.p @ (ocp.model.u - target_input)\n",
    "    ocp.model.cost_expr_ext_cost_e = 0.\n",
    "\n",
    "    # set constraints\n",
    "    ocp.constraints.lbu = np.array([min_force])\n",
    "    ocp.constraints.ubu = np.array([max_force])\n",
    "    ocp.constraints.idxbu = np.array(range(nu))\n",
    "    ocp.constraints.x0 = np.zeros(nx)\n",
    "    ocp.parameter_values = np.ones(ocp.model.p.shape[0])\n",
    "\n",
    "    # set options\n",
    "    ocp.solver_options.qp_solver = 'PARTIAL_CONDENSING_HPIPM'\n",
    "    ocp.solver_options.sim_method_num_stages = 4\n",
    "    ocp.solver_options.nlp_solver_type = 'SQP'\n",
    "    ocp.solver_options.nlp_solver_max_iter = 200\n",
    "    ocp.solver_options.qp_solver_ric_alg = 1  # ? not sure how to set this one\n",
    "    ocp.solver_options.hessian_approx = 'EXACT'\n",
    "    ocp.solver_options.integrator_type = 'DISCRETE'\n",
    "    ocp.solver_options.with_solution_sens_wrt_params = True\n",
    "    ocp.solver_options.with_value_sens_wrt_params = True\n",
    "\n",
    "    # set prediction horizon\n",
    "    ocp.solver_options.tf = Tf\n",
    "\n",
    "    return ocp\n",
    "\n",
    "\n",
    "def create_acados_ocp_solver() -> AcadosOcpSolver:\n",
    "    ocp = create_acados_ocp()\n",
    "    ocp_solver = AcadosOcpSolver(ocp, json_file='acados_ocp.json')\n",
    "    return ocp_solver\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the optimal value of the first control input $u(0)^*$ if we:\n",
    "- set the initial condition as $x_0=[0, 0]^\\top$\n",
    "- set the parameter (cost weight) as the default value $R = 1.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "source": [
    "ocp_solver = create_acados_ocp_solver()\n",
    "ocp_solver.constraints_set(0, 'lbx', np.array([0., 0.]))\n",
    "ocp_solver.constraints_set(0, 'ubx', np.array([0., 0.]))\n",
    "ocp_solver.solve()\n",
    "u0_opt = ocp_solver.get(0, 'u').flatten()[0]\n",
    "print(\"Optimal u is: \", u0_opt)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal value is around 94.8. \n",
    "\n",
    "Now we design a customized neural network (named as `MyNet`) with a MpcLayer as the last layer. The architecture of `MyNet` can be viewed as an MLP + an MpcLayer. In forward propagation, the MLP part takes an initial state $x_0$ as input and gives a set of parameters $p$.  The MpcLayer then uses $p$ as parameters to solve the underlying Optimal Control Problem with an initial state constraint $x(0)=x_0$.\n",
    "\n",
    "Please notice that the MpcLayer does NOT contain any learnable parameters.\n",
    "\n",
    "Our goal in this example is to let the MLP learn to recover the MPC parameters that gives the same optimal input $u(0)^*=94.8$. Ideally, after training, the MLP should return a parameter value that is very close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "source": [
    "class MyNet(nn.Module):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tacados_ocp_layer: AcadosMpcLayer,\n",
    "\t\tinput_dim: int,\n",
    "\t\thidden_dim: int = 32,\n",
    "\t\tnum_hidden_layers: int = 2,\n",
    "\t\tact: nn.functional = nn.functional.relu,\n",
    "\t) -> None:\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.input_dim = input_dim\n",
    "\t\t# Define the input layer\n",
    "\t\tself.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "\t\t# Define the hidden layers\n",
    "\t\tself.hidden_layers = nn.ModuleList()\n",
    "\t\tfor _ in range(num_hidden_layers):\n",
    "\t\t\tself.hidden_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "\n",
    "\t\t# Define the layer that gives mpc parameters\n",
    "\t\tself.mpc_param_layer = nn.Linear(hidden_dim, acados_ocp_layer.np)\n",
    "\n",
    "\t\t# Define the differentiable mpc layer\n",
    "\t\tself.mpc_solver_layer = acados_ocp_layer\n",
    "\n",
    "\t\t# Define activation function\n",
    "\t\tself.activation = act\n",
    "\n",
    "\tdef forward(self, x0):\n",
    "\t\tmpc_params = self.get_mpc_params(x0)\n",
    "\t\taction = self.mpc_solver_layer(x0, mpc_params)\n",
    "\t\treturn action\n",
    "\t\n",
    "\tdef get_mpc_params(self, x0):\n",
    "\t\t\"\"\"\n",
    "\t\tThis function servers as part of the forward() function.\n",
    "\n",
    "\t\tIt performs forward propagation of the neural network until the MPC layer.\n",
    "\t\tThe returned value is the parameters to be passed into the MPC layer.\n",
    "\t\t\"\"\"\n",
    "\t\tx = x0\n",
    "\t\tx = self.activation(self.input_layer(x))\n",
    "\t\tfor hidden_layer in self.hidden_layers:\n",
    "\t\t\tx = self.activation(hidden_layer(x))\n",
    "\t\tmpc_params = torch.nn.functional.relu(self.mpc_param_layer(x)) + 1e-3\n",
    "\t\treturn mpc_params"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can optimize the parameters inside the neural network, using state-of-the-art optimizers in Machine Learning, e.g. ADAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "source": [
    "batch_size = 1\n",
    "X = torch.zeros(batch_size, 2)\n",
    "Y = u0_opt * torch.ones(batch_size, 1)\n",
    "\n",
    "ocp_layer = AcadosMpcLayer(ocp_solver)\n",
    "\n",
    "hidden_dim = 64\n",
    "torch.manual_seed(0)\n",
    "net = MyNet(ocp_layer, 2, hidden_dim, 2)\n",
    "opt = torch.optim.Adam(net.parameters(), lr=2e-3)\n",
    "for _ in range(120):\n",
    "\topt.zero_grad()\n",
    "\tl = torch.nn.MSELoss()(net(X), Y)\n",
    "\tprint(f\"loss: {l.item():.4f},  NN output: {net(X).item():.4f},  MPC params: {net.get_mpc_params(X).item():.4f}\")\n",
    "\tl.backward()\n",
    "\topt.step()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output of optimizer, we can observe the loss decreases to around 0, the output of our custimized network is close to desired value $94.8$, and the MPC parameter given by the MPC part is close to 1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
